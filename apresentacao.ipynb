{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extraÃ§Ã£o do texto do PDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inglÃªs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alvaro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Listagem de palavras frequentes que nÃ£o alteram o significado do texto (em ingles)\n",
    "nltk.download('stopwords')\n",
    "irrelevantes = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/alvaro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/alvaro/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tratamento de flexÃ£o de palavras por lematizaÃ§Ã£o\n",
    "tk = nltk.tokenize.WhitespaceTokenizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "lmt = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#A biblioteca nltk nÃ£o tem dados para lematizaÃ§Ã£o em PT\n",
    "def lematize_text(text):\n",
    "    lem_words = list()\n",
    "    for word in tk.tokenize(text):\n",
    "        lem_words.append(lmt.lemmatize(word))\n",
    "    return lem_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfReader('ArquivosEN/1608.06902.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "textin = reader.pages[0].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n"
     ]
    }
   ],
   "source": [
    "lematizedTXT = lematize_text(textin)\n",
    "print(len(lematizedTXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo elementos ruins - funÃ§Ã£o bem custosa, deve ter alguma que faz isso mais facil\n",
    "for word in lematizedTXT:\n",
    "    for stopword in irrelevantes:\n",
    "        if word == stopword:\n",
    "            lematizedTXT.remove(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "['Recurrent', 'Neural', 'Networks', 'With', 'Limited', 'Numerical', 'Precision', 'Joachim', 'Ott\\x03,', 'Zhouhan', 'Linz,Ying', 'Zhangz,', 'Shih-Chii', 'Liu\\x03,', 'Yoshua', 'Bengiozy', '\\x03Institute', 'Neuroinformatics,', 'University', 'Zurich', 'ETH', 'Zurich', 'ottj@ethz.ch,', 'shih@ini.ethz.ch', 'zDÃ©partement', 'dâ€™informatique', 'et', 'de', 'recherche', 'opÃ©rationnelle,', 'UniversitÃ©', 'de', 'MontrÃ©al', 'yCIFAR', 'Senior', 'Fellow', '{zhouhan.lin,', 'ying.zhang}@umontreal.ca', 'Abstract', 'Recurrent', 'Neural', 'Networks', '(RNNs)', 'produce', 'state-of-art', 'performance', 'many', 'machine', 'learning', 'task', 'demand', 'resource', 'term', 'memory', 'computational', 'power', 'often', 'high.', 'Therefore,', 'great', 'interest', 'optimizing', 'computation', 'performed', 'model', 'especially', 'considering', 'development', 'specialized', 'low-power', 'hardware', 'deep', 'networks.', 'One', 'way', 'reducing', 'computational', 'need', 'limit', 'numerical', 'precision', 'network', 'weight', 'biases.', 'This', 'ha', 'led', 'different', 'proposed', 'rounding', 'method', 'applied', 'far', 'Convolutional', 'Neural', 'Networks', 'Fully-Connected', 'Networks.', 'This', 'paper', 'address', 'question', 'best', 'reduce', 'weight', 'precision', 'training', 'case', 'RNNs.', 'We', 'present', 'result', 'use', 'different', 'stochastic', 'deterministic', 'reduced', 'precision', 'training', 'method', 'applied', 'three', 'major', 'RNN', 'type', 'tested', 'several', 'datasets.', 'The', 'result', 'show', 'weight', 'binarization', 'method', 'work', 'RNNs.', 'However,', 'stochastic', 'deterministic', 'ternarization,', 'pow2-ternarization', 'method', 'gave', 'rise', 'low-precision', 'RNNs', 'produce', 'similar', 'even', 'higher', 'accuracy', 'certain', 'datasets', 'therefore', 'providing', 'path', 'towards', 'training', 'efï¬cient', 'implementation', 'RNNs', 'specialized', 'hardware.', '1', 'Introduction', 'A', 'Recurrent', 'Neural', 'Network', '(RNN)', 'speciï¬c', 'type', 'neural', 'network', 'able', 'process', 'input', 'output', 'sequence', 'variable', 'length.', 'Because', 'nature,', 'RNNs', 'suitable', 'sequence', 'modeling.', 'Various', 'RNN', 'architecture', 'proposed', 'recent', 'years,', 'based', 'different', 'form', 'non-linearity,', 'Gated', 'Recurrent', 'Unit', '(GRU)', '[Cho', 'et', 'al.,', '2014]', 'Long-Short', 'Term', 'Memory', '(LSTM)', '[Hochreiter', 'et', 'al.,', '1997].', 'They', 'enabled', 'new', 'level', 'performance', 'many', 'task', 'speech', 'recognition', '[Amodei', 'et', 'al.,', '2015][Chan', 'et', 'al.,', '2015],', 'machine', 'translation', '[Devlin', 'et', 'al.,', '2014][Chung', 'et', 'al.,', '2016][Sutskever', 'et', 'al.,', '2014],', 'even', 'video', 'game', '[Mnih', 'et', 'al.,', '2015]', 'Go[Silver', 'et', 'al.,', '2016].', 'Compared', 'standard', 'feed-forward', 'networks,', 'RNNs', 'often', 'take', 'longer', 'train', 'demanding', 'memory', 'computational', 'power.', 'For', 'example,', 'take', 'week', 'train', 'model', 'state-of-the-art', 'machine', 'translation', 'speech', 'recognition.', 'Thus', 'vital', 'importance', 'accelerate', 'computation', 'reduce', 'training', 'time', 'networks.', 'On', 'other', 'hand,', 'even', 'run-time,', 'model', 'require', 'much', 'term', 'computational', 'resource', 'want', 'deploy', 'model', 'onto', 'low-power', 'embedded', 'hardware', 'devices.', 'Increasingly,', 'dedicated', 'deep', 'learning', 'hardware', 'platform', 'including', 'FPGAs', '[Farabet', 'et', 'al.,', '2011]', 'custom', 'chip', '[Sim', 'et', 'al.,', '2016]', 'reporting', 'higher', 'computational', 'efï¬ciencies', 'tera', 'operation', 'per', 'second', 'per', 'watt', '(TOPS/W).', 'These', 'platform', 'targeted', 'deep', 'CNNs.', 'If', 'low-precision', 'RNNs', 'able', 'report', 'same', 'performance,', 'saving', 'reduction', 'multiplier', '(the', 'circuit', 'take', 'space', 'energy)', 'memory', 'storage', 'weight', 'would', 'even', 'larger', 'bit', 'precision', 'multiplier', 'needed', '2', '3', 'gate', 'gated', 'RNN', 'unit', 'be', 'reduced', 'the', 'multiplier', 'removed', 'completely.', '1arXiv:1608.06902v2', '[cs.NE]', '26', 'Feb', '2017']\n"
     ]
    }
   ],
   "source": [
    "#Deu certo, mas ainda tem palavras que precisariam ser tratadas\n",
    "print(len(lematizedTXT))\n",
    "print(lematizedTXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existem caracteres estranhos (Ott\\x03,)\n",
    "#Verificar pontuaÃ§Ã£o, ela pode nÃ£o ser tÃ£o importante\n",
    "#Existem alguns trechos em espanhol(?)\n",
    "#Palavras compostas como low-precision\n",
    "#1arXiv:1608.06902v2 (?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PortuguÃªs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alvaro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alvaro/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package floresta to /Users/alvaro/nltk_data...\n",
      "[nltk_data]   Package floresta is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alvaro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /Users/alvaro/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importa dados que vamos usar \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('floresta')   # conjunto de textos em portuguÃªs anotados com etiquetas morfossintÃ¡ticas\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lamatizarPalavra(palavra):\n",
    "    stemmer = RSLPStemmer()     # Removedor de Sufixos da LÃ­ngua Portuguesa\n",
    "    lemma = stemmer.stem(palavra)\n",
    "    if lemma == palavra:\n",
    "        synsets = wordnet.synsets(palavra, lang='por')\n",
    "        if synsets:\n",
    "            lemma = synsets[0].lemmas()[0].name()\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lamatizarTexto(texto):\n",
    "    palavras = texto.split()\n",
    "    stopwordsPT = stopwords.words('portuguese')\n",
    "    textoLematizado = [lamatizarPalavra(palavra.lower()) for palavra in palavras if palavra.lower() not in stopwordsPT]\n",
    "    textoLematizado = ' '.join(textoLematizado)\n",
    "    return textoLematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lamatizarPDF(arquivo :str) -> str:\n",
    "    artigo = PyPDF2.PdfReader(arquivo)\n",
    "    texto = ''\n",
    "    for pagina in artigo.pages:\n",
    "        texto += pagina.extract_text()\n",
    "    return lamatizarTexto(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deep learning red neur convolucionais: reconhec automÃ¡ caract plac licenc automo dieg alv rodrig centr informÃ¡ univers feder paraÃ­b joÃ£ pessoa, 2018 dieg alv rodrig deep learning red neur convolucionais: reconhec automÃ¡ caract plac licenc automotivo. monograf apresent curs ciÃªnc comput centr informÃ¡tica, univers feder paraÃ­ba, requisit obtenÃ§ degree gasbag ciÃªnc computaÃ§Ã£o. orientador: prof. doctor leonard vidal batist novembr 2018 agradec gost registr agradec pais, pedr irene, suport dad perÃ­od gradu , esp elain paci apoi dur perÃ­od dificuldade. agradec espec orientador, prof. doctor leonard vidal batist orient compreens long dess jornada. agradec coleg profes long ano pres time time auxili colabor and curso. amig apoi form diret indiret graduaÃ§Ã£o. resum control trÃ¡feg rodoviÃ¡rio, via pÃºblic privadas, fronteiras, estac determin estacionamento, infring lei trÃ¢nsit exempl taref exig identific veicular, identific feit mei plac licenciament automo regul lei especÃ­ficas. process identific plac necess wear algum tÃ©cn vis computac , camp ganh bast atenÃ§ comunidad cientÃ­f empr long Ãºlt form aument efici cort custos. advent aprendiz profunda, soluÃ§ divers problem vÃªm send pesquisadas. red neur artificiais, espec red neur convolucionais, salt dad term result compar tÃ©cn tradicion s. red neur convoluc mostr extrem well -suced taref envolv princip classificaÃ§Ã£o. trabalh busc demonstr viabil red neur convoluc leit caract plac licenc veicul , obt result infer ord 89,24% caract infer corret . palavr -chave: aprendiz profunda, red neur convolucionais, reconhec , plac licenc veicul abstract controlling road traffic, public or private, borders, parking lots, trespas traffic law are exampl of task that requ licens plat identification, being the licens plat regulated by specific laws. the licens plat identification process, it is necessary the use of som comput vision technic, field that ha gained enough attention of the scientific community and of the compani ov the last ye way to increas efficiency and to cut costs. with the advent of deep learning, solutiom to the most divers probl hav been researched. with artific neur networks, especially of convolut neur networks, jump in term of result compared to tradit method wa given. convolut neur network are extremely successful I N task that mainly involv classification. thil work aim to demonstrat the viability of convolut neur network reading charact in vehicul licens plat , obtaining result on the ord of 89.24% of correctly inferred charact . key-words: deep learning, hundred onvolut neur networks, recognition, licens plat S list figur figur one - exempl red F eedforward (font : nascimento&oliveira, 2016) ... 18 figur 2 - exempl (a) underfitting , (b) overfitting (c) beneficial gener (font : papagelis&kim) ................................ ................................ ................................ ..................... 19 figur three - grÃ¡f funÃ§ sig moid (font : facure, 2017) ................................ ............... twenty figur four - grÃ¡f funÃ§ relu (font : facure, 2017) ................................ ..................... 21 figur 5 - exempl dropout (font : dlb) ................................ ................................ .............. twenty-two figur six - exempl arquitetur lenet problem classif caÃ§ cÃ©lul norm anorm (font : araÃºj et al ., 2017) ................................ .............................. 23 figur 7 - exempl funcionam nto max -pooling filtr 2x2 imag four-wheel_drive (font : ferreira, 2017) ................................ ................................ ................................ .......... 24 figur 8 - exempl arquitetur a, base lenet, utiliz ndo cam bÃ¡sic convoluÃ§ , pooling totalment conect (font : araÃºj et al ., 2017) ............ twenty-five figur nine - exempl fot v eÃ­cul retir du rant fas mont ag banc dad (font : authoress ) ................................ ................................ ................................ ....... 27 figur 10 - imag plac apÃ³ S convers scal cinz equ aliz histogram (font : authoress ) ................................ ................................ ................................ . 28 figur 11 - arquitet cnn implement (font : authoress ) ................................ .......... 28 figur 12 - exempl plac transit vermelh R emov banc imag test trein (font : authoress ) ................................ ................................ .................. thirty figur 13 - exempl plac rem ovid banc trein test alt rot ilumin uniform (font : authoress )................................ ...................... 31 figur 14 â€“ exempl inferÃªnc obt corretam nte (font : authoress ) ................... 32 figur fifteen â€“ err infer R epet (font : authoress ) ................................ ..................... 34 figur 16 â€“ exempl err infer (font : authoress ) ................................ ............... 34 list abreviat pdi â€“ process digit I mag alpr â€“ automatic licens plat recognition ann â€“ artific neur network dnn â€“ deep neur network dl â€“ deep learning cnn â€“ convolut neur network 12 sum one introduÃ§ ................................ ................................ ................................ ....... 13 1.1 tem ................................ ................................ ................................ ...................... fifteen 1.1.1 obje general ................................ ................................ ................................ fifteen 1.1.2 obje especÃ­f ................................ ................................ .................. fifteen 1.2 estrut trabalh ................................ ................................ ............ 16 2 conceit geral ................................ ................................ ........................... 17 2.1 perceptron feedforward ................................ ................................ ..... 17 2.2 funÃ§ erro, gradi descend backpropagation ................................ ................................ ............................ 18 2.3 funÃ§ ativ ................................ ................................ ..................... twenty 2.4 momentum ................................ ................................ ................................ ......... 21 2.5 dropout ................................ ................................ ................................ .............. 21 2.6 dat augmentation ................................ ................................ ........................ twenty-two 2.7 convoluÃ§ ................................ ................................ ................................ ..... twenty-two 2.8 red neur convoluc ................................ ............................. 23 2.8.1 cam convoluc ................................ ................................ ............ 23 2.8.2 cam pooling ................................ ................................ ....................... 24 2.8.3 cam total conect ................................ .......................... twenty-five three metodolog ................................ ................................ ................................ .... 26 3.1 obtenÃ§ banc plac veicul ................................ ..... 26 3.2 obtenÃ§ recort plac veÃ­cul .......................... 27 3.3 process padron imag ................................ .......... 27 3.4 dat augmentation ................................ ................................ ........................ 28 3.5 arquitet red ................................ ................................ ................... 28 3.6 trein red ................................ ................................ .................. twenty-nine four apresent anÃ¡lis result ................................ ........ thirty 5 conclus trabalh futur ................................ ....................... 35 refer ................................ ................................ ................................ ....................... 36 13 one introduÃ§ advent imag digit surg -se necess imediat tÃ©cn process imagens, origin nov camp estudo, denomin process digit imag (pdi). pdi tod process anÃ¡lis manipul imag digitais, identificar, extra inform transform imagem. pdi englob gam softwares, hardw princip fundament teÃ³ricos. exempl divers aplic proced pdi, (queiroz, 2003): â€¢ retific restaur imagens, ond algoritm aplic M inimiz distorÃ§ degrad dad imag poss come apresentar, obje obt imag close cen ; â€¢ realÃ§ imagens, ond obje pass melhor imagem, part dela, best visual ; â€¢ classific imagens, tÃªm final substitu anÃ¡lis ocular dad tÃ©cn quantit anÃ¡lis automÃ¡tica, vis identific reg pres cen . evoluÃ§ mÃ©tod pdi best en tend process manipul imag outr camp pesquis surgiu, vis computacional. segund ballard brown (ballard &brown , 1982 ), camp vis computac pod entend estud process extr informaÃ§Ã£ imagens. vis computac dif pdi med pdi preocup priorit relaÃ§ imag -imagem, ond process S inic imag result imag , vis computac preocup priorit relaÃ§ imag -modelo, ond lev -se imag descr matemÃ¡ (modelos) represent imagens, possibilit infer extr determin caracterÃ­s desej estudar. 14 avanÃ§ tÃ©cn vis computac permit desenvolv sistem problem reconhec automÃ¡ plac licenciamento, ingl automatic licens plat recognition alpr , permit poup capit human vali permit tambÃ© M monitor uniform dad quant cresc veÃ­cul ruas. give_birth control veÃ­cul trafeg rodovia, atravess fronteiras, par estacionamento, pÃºblic privado, import estratÃ©g control trafeg geral. identific veÃ­cul irregul possibilit control penalizaÃ§Ã£o, Ã¢mbit administr penais, infra automa process otimiz cust tempo, torn serviÃ§ tir proveit dess identific eficazes. Ãºlt anos, paÃ­s inglaterra, franÃ§a, est unid canad A implement sistem reconhec automÃ¡ plac licenc coloc pr oduÃ§ sistem real monitor gerenciam nto tr Ã¡feg (jin et al. , 2012) . red neur artific , ingl â€œ artific neur networksâ€ , exist bast temp (rosenblatt , 1958) . cri doctor frank rosenblatt , anm posteri deriv compÃµ hoj divers tÃ©cn aprendiz gem profund dispon base funcion S neurÃ´ni cÃ©rebr humano. ann S atra mai atenÃ§ comunidad acadÃªm indÃºstr , Ãºlt dÃ©c , advent R ede neur profundas, ingl â€œdeep neur network â€, transform divers camp , espec camp vis computac , process sinais, audi fal process lingu natur . aprendiz profund o, ingl Ãªs â€œdeep learning â€, form conhec refer dnn s. tÃ©cn dnm bast poder difund red neur convolucionais, ingl â€œ convolut neur network â€, cnm . S avanÃ§ recent arquitet process plac grÃ¡ficas, gpu , mai pod computacional, memÃ³r dispon acessibil recurs , possibilit wear desenvolv intens soluÃ§ utiliz cnm , mostr ado promis S resoluÃ§ problem aprendizado, espec classificaÃ§Ã£o. fifteen aplic model cnm resolv problem reconhec automÃ¡ plac licenc surg opÃ§ possi vi tradic tÃ©cn ca vis computac aprend mÃ¡quin existentes, utiliz comercialmente, resolv problem especÃ­fico. 1.1 tem trabalh tema, tÃ­tul sugere, deep learning Ãªnfas wear cnm resolv pro blem reconhec caract plac veiculares. tend hipÃ³tes possibil resolv problem apen wear cnn , remov -se etap segment caracteres, common sistem busc resolv problem . 1.1.1 obje general demonstr viabil resoluÃ§ problem reconhec plac licenc veicul utiliz apen cnn . 1.1.2 obje especÃ­f â€¢ cri bas dad plac licenc veicul brasil ; â€¢ desenvolv cnn process classific dÃ­git plac veiculares; â€¢ demonstr viabil tema. 16 1.2 estrut trabalh pres trabalh divid quatr seÃ§ . prim seÃ§ cont vis introdutÃ³r tem well contextu problemÃ¡tica, inclu obje apresent trabalho. segund seÃ§ trat conceit refer teÃ³r assunto, fornec conceit essenc entend seÃ§ seguintes. terc seÃ§ abordan result obt discut result quart seÃ§ trat sobr trabalh futur faz conclus acerc tema. 17 2 conceit geral introduz nest porÃ§ trabalh algum conceit relev tema. give_birth mo utilizados, well acrÃ´nimos, ingl , virtud vast utiliz public artig acadÃªmicos. 2.1 perceptron feedforward base trabalh warren s. mcculloch walt pitt (mcculloch &pitt , 1943) , 1958, frank ros nblatt (rosenblatt , 1958) cri conceit bÃ¡sic base funcion neurÃ´ni human s, perceptron . basicamente, perceptron realiz oper sobr entr ğ‘¥ğ‘–, cad entr associ pes ğ‘¤ğ‘–, realiz somatÃ³ri produt escal ğ‘¥ğ‘–. ğ‘¤ğ‘– somatÃ³ri adic bia ğ‘. result obt ent adicion funÃ§ ativ ğœ conhec funÃ§ degrau, funÃ§ heavisid , produz result 0 , result men alike 0 one result mai zer . ğ‘“(ğ‘¥)={0, ğ‘+âˆ‘ğ‘¤ğ‘–.ğ‘¥ğ‘– ğ‘–â‰¤0 1, ğ‘+âˆ‘ğ‘¤ğ‘–.ğ‘¥ğ‘– ğ‘–>0 dad saÃ­d binÃ¡ria, perceptron consider classific bin men red neur tip feedforward . red neur tip feedforward red neur propag apen direÃ§Ã£o, seja, input entr perceptrom gesture propag saÃ­d Ãºnic direÃ§Ã£o, retorn gesture entrada. anm norm possu multipl camadas, send cam entrada, cam saÃ­d cam ocult localiz entr saÃ­da. red feedforward pod multicamadas, signif cam , ond saÃ­d cam entr outr imediat posteri hierarquicamente. exempl red feedforward pod vist figur abaixo: 18 figur one - exempl red feedforward (fonte: nascimento&oliveira, 2016) 2.2 funÃ§ err , gradi descend backpropagation anm aprend atravÃ©s process ajust pes entr cad camada, ajust dess pes necessit defin form calcul quÃ£ prÃ³x result correto, ago necessÃ¡r funÃ§ erro, normalm nte med quÃ£ imprecis red dad result esperado. funÃ§ err inclu mean squ err , bast utiliz problem regress cros -entropy , problem classific comu utiliz ( mccaffrey , 2013). cÃ¡lcul cross-entropy , entrop cruzada, utiliz seguint equaÃ§ , abaix discrimin , ond W uterus pesos, ğ‘¦ğ‘– ğ‘¡ğ‘– result infer correto, respectivamente, ğ‘› nÃºmer entire it treinamento. ğ¸(ğ‘¤)=1 ğ‘›âˆ—âˆ‘[ğ‘¡ğ‘–âˆ—log (ğ‘¦ğ‘–)+(1âˆ’ğ‘¡ğ‘–)âˆ—log (1âˆ’ğ‘¦ğ‘–)]ğ‘› ğ‘–=1 dito, precis ajust pes ating result desej algoritm utiliz realiz such taref , inform entr saÃ­d desejada, backpropagation gradi descendente. 19 form gener algoritm func ind caminh invers dados, ind saÃ­d retorn cam cam red neur , ajust val pes ğ‘¤, potential red aprend padr sobr dados, entr red entr nunc vista, red able reconhec padr aprend anteriormente, entr possu ruÃ­d (barc et al, 2005) . gradi descend que, form iter , val pes alter backpropagation segu pass fixo, cham tax aprendizagem. obje gradi descend minim funÃ§ err men err local , necessit cuid escolh tax ap rendizado, poi impact diret temp necess cheg mÃ­nimo. red general sufici aprend dad entr utiliz process trein red (process dad inser indic saÃ­d vÃ¡lida), cham overfitting . cas D red general demal detect padr form correta, cham underfitting . (a) (b) (c) figur 2 - exempl (a) underfitting, (b) overfitting (c) beneficial gener (fonte: papagelis&kim) algoritm atu red conjunt feedforward , ond excursion calcul err volt pes ajustados. observ algoritm gradi descend fat encontr mÃ­n local funÃ§ erro, pod lev result consider red Ã³tim , N Ã£o best pod ating (mÃ­n global). twenty 2.3 funÃ§ ativ funÃ§ ativ import part anm , poi determin saÃ­d cad perceptron (ou neurÃ´nio). wear funÃ§ line funÃ§ ativ lim ita pod anm soluÃ§ convexas. soluÃ§ - convexas, funÃ§ line necessÃ¡rias. princip funÃ§ utiliz pod vist segu (facure, 2017) : â€¢ funÃ§ sigmoide: conhec funÃ§ logÃ­stica, funÃ§ sigmoid dad equaÃ§Ã£o: ğœ(ğ‘¥)=1 1+ğ‘’âˆ’ğ‘¥ assum val apen 0 (nÃ£ ativaÃ§Ã£o) one (ativaÃ§Ã£o). comport bast parec prÃ³pri neurÃ´ni biolÃ³gicos, ativ S dad entr receb . figur three â€“ grÃ¡f funÃ§ sigmoid (fonte: facure, 2017 ) â€¢ line retific (relu) : retorn 0 val actual mai zero. semelh funÃ§ identidade, dif funÃ§ anteriores, ond propag gradi desvanec R egi cauda, mostr bast easy otimizar. altern bast utiliz prÃ¡tica. fÃ³rmul Ã©: ğ‘…ğ‘’ğ¿ğ‘ˆ (ğ‘¥)=max (0,ğ‘¥) 21 figur four â€“ grÃ¡f funÃ§ relu (fonte: facure, 2017 ) 2.4 momentum term momentum adiÃ§ feit cÃ¡lcul gradi descendente, ond term const defin quÃ£ mudanÃ§ pes anteri afet mudanÃ§ pes atual. possu val 0 1, ond 0 signif mudanÃ§ depend apen funÃ§ err one depend apen mudanÃ§ anteri peso. prÃ¡t , term momentum us imped gradi descend fiqu pres mÃ­n locais, minimiz desvant algoritmo. 2.5 dropout dropout tÃ©cn utiliz P ara aument quant padr red detect mesm entrada. process dÃ¡ realiz remoÃ§ aleatÃ³r neurÃ´ni cam ocult dur trein min lot entrada, ond neurÃ´ni reinser concluding P rocess min lote. tÃ©cn ajud evit overfitting . represent tÃ©cn pod vist abaixo: twenty-two figur 5 - exempl dropout (fonte: dlb) 2.6 dat augmentation dat augmentation mÃ©tod regular ba st import imped overfitting . sempr possuÃ­m conjunt trein grand sufici red aprend padr desejamos, torn difficult resoluÃ§ problem banc dad trein pequenos. process dat augmentation utiliz divers tÃ©cn aument dad form artific como: vari brilho, saturaÃ§Ã£o, zoom, reflex horizont vertical, recorte, outr mÃ©todos. tÃ©cn consegu melhor result red adicion nenhum caracterÃ­s nov aprendida, reduz form drÃ¡s overfitting , torn red robusta. 2.7 convoluÃ§ matematicamente, convoluÃ§ oper line receb dua funÃ§ entr retorn terc funÃ§ originÃ¡r somatÃ³ri multiplic funÃ§ kernel reg superpost funÃ§ alv desloc kernel sobr ela. formul convoluÃ§ domÃ­ni discret seguinte: (ğ‘“âˆ—ğ‘”)(ğ‘˜)=â„(ğ‘˜)=âˆ‘ğ‘“(ğ‘–)âˆ™ğ‘”(ğ‘˜âˆ’ğ‘–)ğ‘˜ ğ‘–=0 23 F G sequenci numÃ©r tamanh igual variad os, funÃ§ retorn K -Ã©s element somatÃ³ri multiplicaÃ§Ã£o. 2.8 red neur convoluc ingl convolution al neur network (cnm ), cnm tip especÃ­f ann , propost pesquis franc yann lecun (lecun, et al. , 1998) . cnm mostraram, desd criaÃ§Ã£o, ser eficaz resolv problem classificaÃ§Ã£o, mostr altern vi mÃ©tod tradic tip problema. desvant cnm fat exist necess U ma grand quant dad rotul extr padrÃµes, featur . basicamente, extr dess featur , pod exist proceed trÃª compon bÃ¡sic cnn , cam convoluÃ§Ã£o, pooling red total conectada. qualqu arquitet bÃ¡sic compost blocos. exempl red cri yann lecun, lenet pod vist abaixo: figur six - exempl arquitet lenet problem classific cÃ©lul norm anorm (fonte: araÃºj T al., 2017) 2.8.1 cam convoluc cam convoluc cnn respons extra cham featur entrada. process extr dess featur dÃ¡ mei filtr convoluc tamanh reduzidos, ond filtr percorr dad entr 24 largura, altur profund (cham dimensÃ£o) realiz oper convoluÃ§ sobr dados. cad process entr perÃ­od trein rede, filtr ineffective send ajust such mod dispar entr contiv determin caracterÃ­s common lot entrada, exemplos, arestas, cores, dentr outr caracterÃ­sticas. and entr rede, filtr ineffective aprend estrut cad turn complexas, seja, quant ma is filtr convolucionais, featur extraÃ­m entrada, however cust memÃ³r processamento, precis balance hor defin arquitetura. 2.8.2 cam pooling cam pooling cons basic cam dest nad reduz tamanh dad entrada. normalmente, subsequently cam convolucon utiliz cam pooling , prÃ³x cam convoluÃ§ receb outr form represent dados, possibilit red aprend divers represent dados, evit overfitting (karpathy ). tÃ©cn bast utiliz execut pooling cham max- pooling . ness tÃ©cnica, reduz subpart dad orig mai val encontr ness sub regiÃµes, reduz tamanh imag fat filtr ğ‘š ğ‘¥ ğ‘›. figur 7 - exempl D funcion max -pooling filtr 2x2 imag four-wheel_drive (fonte: ferreira, 2017) twenty-five tÃ©cn pooling benefic red neur , pass reduz quant dad cam seguint melhor regular rede, reduz cust memÃ³r processamento. 2.8.3 cam total conect cam total conect norm situ concluding rede. ness cam featur extra cam convoluÃ§ anteri utiliz give_birth saÃ­d classific rede. exempl arquitet trÃª cam bÃ¡sic pod encontr abaixo: figur 8 - exempl arquitetura, base lenet, utiliz cam bÃ¡sic convoluÃ§Ã£o, pooling total conect (fonte: araÃºj et al., 2017) 26 three metodolog pres trabalh segu abord metodolÃ³g qualitativa. result apresent underneath form conclus extraÃ­das. obtenÃ§ S refer R esultados, algum pass segu D iscrimin S seguir. 3.1 obtenÃ§ banc plac veicul prim passo, decid -se banc imag plac obt form manual, seja, banc imag prÃ³pri cri escolh ufpb, campu i, tom fotos. local enorm nÃºmer veÃ­cul estacionamentos, ufpb possibilit rÃ¡pid aquis fot veÃ­culos. etap obtenÃ§ banc dad abert process nÃºmer 23074.010615/2018 -13 junt prefeit universitÃ¡r univers feder paraÃ­ba. processo, solicit autor fotograf veÃ­cul estacion campu i. dev autor mÃ£o process tom imag iniciado. aquis imag utiliz cÃ¢m marc canon , model rebel t2i , configur mod man seguint parÃ¢metr finidos: â€¢ iso aut : mÃ¡x.:400 â€¢ comp.exp./aeb : 0 â€¢ wb shift/bkt : 0,0/ Â±0 â€¢ dispar flash : desactiv â€¢ qual : liter configur acim busc zer mÃ¡x configur melhor ilumin imag captur mai fidel potential . 27 figur nine - exempl fot veÃ­cul retir dur fas mont banc dad (fonte: autor) retir 800 imag comp banc 2 turnos. restr privac exig prefeit universitÃ¡r liber fotos, apen veÃ­cul authoress mostr exemplo. 3.2 obtenÃ§ recort plac veÃ­cul record plac utiliz ferrament onlin cham supervisely. imag veÃ­cul plac segment form man atravÃ©s ferrament onlin , disponibil form gratuit pesquisa, send export format json. subsequently process segment manual, script desenvolv au tor utiliz lingu python execut cad 800 imagens, recort plac S imag ns atravÃ©s marc feit supervisely . 3.3 process padron imag subsequently obtenÃ§ recort placas, imag convert escal cinz submet process equal histograma. tarefa, U M script desenvolv autor, lingu python, utiliz bibliotec manipul imag cÃ³dig aberto, opencv . 28 figur 10 - imag plac subsequently convers escal cinz equalizaÃ§Ã£ histogram (fonte: autor) 3.4 dat augmentation conform cit refer teÃ³rico, cnm necessit grand quant dad entr treinamento, tamanh banc dad 800 imag divid inic hundred imag P ara test 700 imag treinamento, send consider nÃºmer baix imag treinamento. tÃ©cn dat augmentation mostr Ãºteis, ond aument -se banc imag four vez tamanh original, 800 3200 imag . aind nÃºmer baixo, trabalh propÃµe, satisfatÃ³rio. 3.5 arquitet red seguint arquitet cnn implement ap efetu classific plac : figur 11 - arquitet cnn implement (fonte: autor) entrada: imag 128x48cam convolucionalcam pooling: maxpool: 2x2, strid 2x2cam convoluc cam pooling: maxpool: 2x2, strid 2x2cam convolucionalcam pooling: maxpool: 2x2, strid 2x2cam convoluc cam pooling: maxpool: 4x4, strid 3x2cam total conectadasaÃ­da: array 7x36 twenty-nine arquitet acima, vem four cam convoluÃ§ , cad one cam pooling adjac ond prim receb imag tamanh original, 128x48, Ãºlt reduz imag tamanh 6x1. 3.6 trein red serve celer process trein red foi-s utiliz plac grÃ¡f ( gpu ) marc evg chipset nvid 1080 information_technology 11gb memÃ³r gddr5x, process intel i7 4790k 16 gb memÃ³r ram ddr3 marc corsa , model vengeanc pro. sistem operac utiliz microsoft window 10 pro. thirty four apresent anÃ¡l result pres trabalh obtev result satisfatÃ³ri propunha. obje inic , demonstr viabil resoluÃ§ problem reconhec plac licenc veicul utiliz apen cnn , trabalh obtev result tax mÃ©d acert caract 89,24% plac int 49,22%. N ormal banc necessÃ¡ria, ond algum plac lev cas isol como, exemplo, plac carr rental ser vermelh lev pouc cas caract paint branca, remov banc test treinament o. figur 12 - exempl plac transit vermelh remov banc imag test trein (fonte: autor) plac alt degree rot retir banc trein teste, vist baix ocorr interfer trein rede. outr problem sombr parc demasi alt degree luminos natur fat interfer bast trein aument precis infer , vist prÃ© -process equal histograma, permanec -se problema. plac letr pouc vist motiv err infer caracteres. red grand sucess acert caract numÃ©r vist possivel idad 10 caract disponibil caract numÃ©r plac trein red vasta. 31 figur 13 - exempl plac remov banc trein test alt rot ilumin uniform (fonte: autor) concluding process normal rest -se bas dad entire 2820 imagens. obtenÃ§ nÃºmer acert apresent previamente, tÃ©cn conhec valid cruz tip k-fold utilizada. -se utiliz apen grup trein teste, grup valid ignorado. 2820 imag divid 10 grup mutu exclud 282 imag ( ğ‘˜=10), -se realiz prim trein (ch ada prim iter autor) utiliz grup ( fold) one test rest treinamento. posteri cad grup foi, form iterativa, assum pos grup test grup 10. result obt pod encontr tabel seguir: tabel 1: result obt subsequently ğ’Œ=ğŸğŸ test % acert caract % acert plac cust trein 1Âª iter 93,4 57,09 0.3544 2Âª iter 84,54 33,69 0.5532 3Âª iter 90,33 52,83 0.5363 4Âª iter 85,28 40,07 0.5414 5Âª iter 96,18 76,24 0.611 6Âª iter 85,71 34,04 0.3175 7Âª iter 89,07 48,22 0.6368 8Âª iter 93,27 65,25 0.3501 32 9Âª iter 83,61 32,98 0.557 10Âª iter 90,96 51,77 0.3008 mÃ©d 89,24 49,22 0.475857 exemplific resultados, segu imag algum infer obt Ãªxito: figur 14 â€“ exempl infer obt corret (fonte: autor) dur process valid cruzada, iteraÃ§Ãµes, uterus confus cri vis demonstr err red serve nort sobr qual ond concentr err infer cnn . seg tabel uterus confus ond legend hundred indic val corret I val I nfer : 33 tabel 2: uterus confus origin iter realiz c/i F G M N Q R X 6.66% 20% 20% hundred 16.66 % D 12.5% I 4.34% K 9.52% liter 25% M Q 0.62% 1.25% T 40% 10% 10% Z 7.69% 0 one 2 5 8 c/i upsilon Z 0 one 2 four 5 7 nine 20% 6.66% hundred D I K liter M 1.78% Q T 10% 10% 20% Z 15.38 % 0 0.76% one 0.9% 0.9% 0.9% 2 1.02% 5 0.99% 0.99% 8 1.01% 34 uterus confusÃ£o, pod observ cl divis acentu err letr -letr err nÃºmer -nÃºmero, mostr red foi, iter pesquisada, well relaÃ§ entend padr three letr segu four nÃºmer pres plac licenc automo brasileiras. dur process construÃ§ uterus cas err interess S mostr well pres list err err caract nÃºmer infer repetid form incorret , doi exempl ilustr cas especÃ­fico: figur fifteen â€“ err infer repet (fonte: autor) rest err mostr bast lig quant caract pres teste, seja, baix ocorr determin caractere. segu exempl outr err apresent rede: figur 16 â€“ exempl err infer (fonte: autor) 35 5 conclus trabalh futur pres trabalh ating obje general especÃ­ficus, med cri bas dad plac licenc veicul brasileiras, desenvolv cnn process plac obtev result demonstr viabil tema. obje trabalh desenvolv sistem pud utiliz comercialmente, portant algum taref pod feit trabalh futur como: â€¢ test degree acurÃ¡c infer feit part banc test ger computador; â€¢ realiz crÃ­t sobr dad exempl fat exist padr aaa9999 dad lev consider inferÃªncias; â€¢ constru banc dad road comput reconhec nov plac mercosul; â€¢ alter arquitet red form radic test level influ sobr inferÃªncias; â€¢ test outr arquitet exist cnn . 36 refer araÃºj , flÃ¡vi h. d. ; carn , allan c. ; silv , romu r. v. ; med , fÃ¡t n. s. ; ushiz , daniel m. red neur convoluc tensorï¬‚ow: teor prÃ¡t . iii escol region informÃ¡ piauÃ­. livr anal - artig minicursos, v. 1, n. 1, p. 382 -406, jun, 2017. dispon em: http://www.eripi.com.br/2017/images/anais/minicursos/7.pdf . acess em: one 5 out. 2018. barc , mar carolin stockl ; silv , tiag red siqu ; magin , marci . trein red neur artificiais: algoritm backpropagation . in: ix encontr latin americ inici cientÃ­f v encontr latin americ pÃ³ -graduaÃ§Ã£o, univers val paraÃ­ba. val paraÃ­ba: univap; 200 5. p. 46-49. dispon em: http://www.inicepg.u nivap.br/cd/inic_2005/inic/ic1%20anais/ic1 -17.pdf . acess em: 12 out. 2018. dpl, deep learning book. capÃ­tul 23 â€“ func dropout? . dispon em: http://deeplearningbook.com.br/capitul -23-c -func -o-dropout/ . acess em: one four out. 2018. facure, matheus. funÃ§ ativ - entend import ativ corret red neur , 2017 . dispon em: https://matheusfacure.github.io/2017/07/12/activ - func/ . acess em: one four out. 2018. ferreira, lessandr santos. red neur conv oluc profund detecÃ§ plant dan lavo soj . dissert mestrado, univers feder mat gross southland , 2017 . dispon em: http://www.gpec.ucdb.br/pistori/orientacoes/dissertacoes/alessandro2017.pdf . acess em: one 5 out. 2018. jin, lisheng ; Xian , huac ; bie, jing; sun , yuqin ; hou , haijing ; niu, qingning . licens plat recognition algorithm passeng car in chines resident are . sensor (basel), p. 8355 â€“8370, 2012. dispon : https://www.ncbi.nlm.nih.gov/pubmed/22969404 . acess em: twenty-five out . 2018. karpathy, a. cs231n convolut neur network ocular recognition . dispon em: http://cs231n.github.io/convolut -networks/. acess em: fifteen out. 2018. lecun , y.; bott , l.; bengi , y.; haffn , p. gradient -based learning applied to document recognition . proc. of the ieee, nov.,. 1998. dispon em: http://yann.lecun.com/exdb/publis/pdf/lecun -01a.pdf . acess em: one four out. 2018. mccaffrey , jam d. why you should us cros -entropy err instead of classification err or mean squared err neur network classifi training . 2013. dispon em: https://jamesmccaffrey.wordpress.com/2013/11/05/why -you-should -use-cros -entropy -err - 37 instead -of-classification -err -or-mean -squared -err -for-ne -network -classifi -training/ . acess em: 12 out. 2018. mcculloch, warren s.; pitts, W alter. logic calculu of the ide immanent in nerv activity . bulletin of mathematic biophysic , vol. 5, p. 115 -133, 1943. dispon em: https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf. acess em: 11 out. 2018. nascimento, e. o.; oliveira, l. n. sensitivity analysil of cutting forc on milling proces using factor experiment planning and ne ural networks. iee latin amer transactiom , vol. 14, n. 12, p. 4811 -4820, 2016. dispon em: https://www.researchgate.net/publication/312027170_sensitivity_analysis_of_cutting_forc _on_milling_process_using_factorial_experimental_planning_and_artific ial_neural_netw rks. acess em: one 2 out. 2018. papagelis, anthony j.; kim, dong soo. backpropagation . dispon em: https://www.cse.unsw.edu.au/~cs9417ml/mlp2/backpropagation.html. acess em: one three out. 2018. queiroz, corin jar de. anÃ¡lis transform geomÃ©tr georreferenc imag satÃ©lit cb -i. dissert mestrado. ufrg - cepsrm, 2003. dispon em: http://hdl.handle.net/10183/6349. acess em: 23 out. 2018. rosenblatt, F . the perceptron: probabilistic mo del information storag and organization in the brain. psychologic review , vol. 65, nÂº 6, p. 386 -408, 1958. dispon em: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.335.3398 . acess em: 11 out. 2018.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamatizarPDF('ArquivosPT/DAR20052019.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57e513fe18a804ff3cd60649239638e0ab0ce36b6125e67c2c7b9b2b4c9b822f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
