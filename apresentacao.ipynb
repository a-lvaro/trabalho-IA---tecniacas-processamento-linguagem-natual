{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extração do texto do PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'ox' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n ox ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rafae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Listagem de palavras frequentes que não alteram o significado do texto (em ingles)\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "irrelevantes = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rafae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rafae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tratamento de flexão de palavras por lematização\n",
    "tk = nltk.tokenize.WhitespaceTokenizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "lmt = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#A biblioteca nltk não tem dados para lematização em PT\n",
    "def lematize_text(text):\n",
    "    lem_words = list()\n",
    "    for word in tk.tokenize(text):\n",
    "        lem_words.append(lmt.lemmatize(word))\n",
    "    return lem_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfReader('ArquivosEN/1608.06902.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "textin = reader.pages[0].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n"
     ]
    }
   ],
   "source": [
    "lematizedTXT = lematize_text(textin)\n",
    "print(len(lematizedTXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo elementos ruins - função bem custosa, deve ter alguma que faz isso mais facil\n",
    "for word in lematizedTXT:\n",
    "    for stopword in irrelevantes:\n",
    "        if word == stopword:\n",
    "            lematizedTXT.remove(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n",
      "['Recurrent', 'Neural', 'Networks', 'With', 'Limited', 'Numerical', 'Precision', 'Joachim', 'Ott\\x03,', 'Zhouhan', 'Linz,Ying', 'Zhangz,', 'Shih-Chii', 'Liu\\x03,', 'Yoshua', 'Bengiozy', '\\x03Institute', 'Neuroinformatics,', 'University', 'Zurich', 'ETH', 'Zurich', 'ottj@ethz.ch,', 'shih@ini.ethz.ch', 'zDépartement', 'd’informatique', 'et', 'de', 'recherche', 'opérationnelle,', 'Université', 'de', 'Montréal', 'yCIFAR', 'Senior', 'Fellow', '{zhouhan.lin,', 'ying.zhang}@umontreal.ca', 'Abstract', 'Recurrent', 'Neural', 'Networks', '(RNNs)', 'produce', 'state-of-art', 'performance', 'many', 'machine', 'learning', 'task', 'their', 'demand', 'resource', 'term', 'memory', 'computational', 'power', 'often', 'high.', 'Therefore,', 'great', 'interest', 'optimizing', 'computation', 'performed', 'model', 'especially', 'considering', 'development', 'specialized', 'low-power', 'hardware', 'deep', 'networks.', 'One', 'way', 'reducing', 'computational', 'need', 'limit', 'numerical', 'precision', 'network', 'weight', 'biases.', 'This', 'ha', 'led', 'different', 'proposed', 'rounding', 'method', 'applied', 'far', 'only', 'Convolutional', 'Neural', 'Networks', 'Fully-Connected', 'Networks.', 'This', 'paper', 'address', 'question', 'how', 'best', 'reduce', 'weight', 'precision', 'training', 'case', 'RNNs.', 'We', 'present', 'result', 'use', 'different', 'stochastic', 'deterministic', 'reduced', 'precision', 'training', 'method', 'applied', 'three', 'major', 'RNN', 'type', 'tested', 'several', 'datasets.', 'The', 'result', 'show', 'weight', 'binarization', 'method', 'not', 'work', 'RNNs.', 'However,', 'the', 'stochastic', 'deterministic', 'ternarization,', 'pow2-ternarization', 'method', 'gave', 'rise', 'low-precision', 'RNNs', 'produce', 'similar', 'even', 'higher', 'accuracy', 'certain', 'datasets', 'therefore', 'providing', 'path', 'towards', 'training', 'efﬁcient', 'implementation', 'RNNs', 'specialized', 'hardware.', '1', 'Introduction', 'A', 'Recurrent', 'Neural', 'Network', '(RNN)', 'is', 'speciﬁc', 'type', 'neural', 'network', 'is', 'able', 'process', 'input', 'output', 'sequence', 'variable', 'length.', 'Because', 'this', 'nature,', 'RNNs', 'suitable', 'sequence', 'modeling.', 'Various', 'RNN', 'architecture', 'been', 'proposed', 'recent', 'years,', 'based', 'different', 'form', 'non-linearity,', 'the', 'Gated', 'Recurrent', 'Unit', '(GRU)', '[Cho', 'et', 'al.,', '2014]', 'Long-Short', 'Term', 'Memory', '(LSTM)', '[Hochreiter', 'et', 'al.,', '1997].', 'They', 'have', 'enabled', 'new', 'level', 'performance', 'many', 'task', 'a', 'speech', 'recognition', '[Amodei', 'et', 'al.,', '2015][Chan', 'et', 'al.,', '2015],', 'machine', 'translation', '[Devlin', 'et', 'al.,', '2014][Chung', 'et', 'al.,', '2016][Sutskever', 'et', 'al.,', '2014],', 'even', 'video', 'game', '[Mnih', 'et', 'al.,', '2015]', 'Go[Silver', 'et', 'al.,', '2016].', 'Compared', 'standard', 'feed-forward', 'networks,', 'RNNs', 'often', 'take', 'longer', 'train', 'demanding', 'memory', 'computational', 'power.', 'For', 'example,', 'take', 'week', 'train', 'model', 'state-of-the-art', 'machine', 'translation', 'speech', 'recognition.', 'Thus', 'is', 'vital', 'importance', 'accelerate', 'computation', 'reduce', 'training', 'time', 'such', 'networks.', 'On', 'the', 'other', 'hand,', 'even', 'run-time,', 'these', 'model', 'require', 'much', 'term', 'computational', 'resource', 'we', 'want', 'deploy', 'a', 'model', 'onto', 'low-power', 'embedded', 'hardware', 'devices.', 'Increasingly,', 'dedicated', 'deep', 'learning', 'hardware', 'platform', 'including', 'FPGAs', '[Farabet', 'et', 'al.,', '2011]', 'custom', 'chip', '[Sim', 'et', 'al.,', '2016]', 'reporting', 'higher', 'computational', 'efﬁciencies', 'up', 'tera', 'operation', 'per', 'second', 'per', 'watt', '(TOPS/W).', 'These', 'platform', 'are', 'targeted', 'deep', 'CNNs.', 'If', 'low-precision', 'RNNs', 'are', 'able', 'report', 'the', 'same', 'performance,', 'the', 'saving', 'the', 'reduction', 'multiplier', '(the', 'circuit', 'take', 'the', 'space', 'energy)', 'memory', 'storage', 'the', 'weight', 'would', 'even', 'larger', 'a', 'the', 'bit', 'precision', 'the', 'multiplier', 'needed', 'the', '2', 'to', '3', 'gate', 'the', 'gated', 'RNN', 'unit', 'can', 'be', 'reduced', 'the', 'multiplier', 'removed', 'completely.', '1arXiv:1608.06902v2', '[cs.NE]', '26', 'Feb', '2017']\n"
     ]
    }
   ],
   "source": [
    "#Deu certo, mas ainda tem palavras que precisariam ser tratadas\n",
    "print(len(lematizedTXT))\n",
    "print(lematizedTXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existem caracteres estranhos (Ott\\x03,)\n",
    "#Verificar pontuação, ela pode não ser tão importante\n",
    "#Existem alguns trechos em espanhol(?)\n",
    "#Palavras compostas como low-precision\n",
    "#1arXiv:1608.06902v2 (?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a7084dce4a57fabdb294815b03e7954449d6920124286f14e8400459bb21104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
